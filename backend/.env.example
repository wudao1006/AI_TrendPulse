# ==========================================
# Core Infrastructure (核心基础设施)
# ==========================================

# Database Connection String / 数据库连接字符串
# Format: postgresql://user:password@host:port/dbname
DATABASE_URL=postgresql://user:password@localhost:5432/ai_sentiment

# Redis Connection URL / Redis 连接字符串
# Used for Celery task queue and caching. / 用于 Celery 任务队列和缓存。
REDIS_URL=redis://localhost:6379/0

# ==========================================
# Security & Auth (安全与鉴权)
# ==========================================

# 后端 API 访问密钥 (客户端需在 Header 中带上 Authorization: Bearer <API_KEY>)
API_KEY=secret-key-123

# ==========================================
# LLM Configuration (大模型配置)
# ==========================================

# LLM Provider API Key / LLM 服务商 API 密钥
# Example: sk-..., or key for DeepSeek/Claude. / 例如 OpenAI sk-... 或 DeepSeek/Claude 的 Key。
LLM_API_KEY=your_llm_api_key

# LLM Base URL / LLM 接口基地址
# Compatible with OpenAI format. / 兼容 OpenAI 格式的接口地址。
# Examples: https://api.openai.com/v1, https://api.deepseek.com/v1
LLM_API_BASE_URL=https://api.openai.com/v1

# Model Name / 模型名称
# Recommend models with good instruction following capabilities. / 推荐使用指令遵循能力强的模型。
# Examples: gpt-4-turbo, gpt-3.5-turbo, deepseek-chat
LLM_MODEL=gpt-4-turbo

# ==========================================
# Platform APIs (第三方平台 API)
# ==========================================

# --- Reddit ---
# Reddit App Client ID / Reddit 应用 ID
# Create at https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=your_client_id

# Reddit App Client Secret / Reddit 应用密钥
REDDIT_CLIENT_SECRET=your_client_secret

# User Agent for Reddit API / Reddit API 的 User Agent
# Format: app-name/version
REDDIT_USER_AGENT=ai-sentiment-bot/1.0

# --- YouTube ---
# Google Cloud API Key for YouTube Data API v3 / YouTube Data API v3 密钥
# Enable "YouTube Data API v3" in Google Cloud Console. / 需在 Google Cloud Console 启用该 API。
YOUTUBE_API_KEY=your_youtube_api_key

# --- X (Twitter) ---
# X Scraper is based on Playwright and requires valid cookies. / X 爬虫基于 Playwright，需要有效 Cookie。

# Path to local JSON file containing accounts / 包含账号信息的本地 JSON 文件路径
# Format: [{"cookies": [...]}, ...]
X_ACCOUNTS_PATH=

# JSON string containing accounts (Environment Variable alternative) / 包含账号信息的 JSON 字符串（环境变量方式）
# Useful for Docker/Cloud deployment where file access is tricky. / 适用于 Docker 或云部署。
X_ACCOUNTS_JSON=

# Run browser in headless mode? / 是否以无头模式运行浏览器？
# true: Invisible (Production); false: Visible (Debugging) / true: 隐藏界面（生产）；false: 显示界面（调试）
X_HEADLESS=true

# HTTP Proxy for X / X 平台的 HTTP 代理
# Format: http://user:pass@host:port
X_PROXY=

# Page load timeout (ms) / 页面加载超时时间（毫秒）
X_TIMEOUT_MS=30000

# Max consecutive errors before pausing an account / 账号暂停前的最大连续错误数
X_ACCOUNT_ERROR_LIMIT=3

# ==========================================
# Application Config (应用配置)
# ==========================================

# Debug Mode / 调试模式
# Enables verbose logging and reloading. / 开启详细日志和热重载。
DEBUG=true

# Log Level / 日志等级
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Analysis Text Truncation / 分析文本截断长度
# Max length of text sent to LLM for analysis per item. / 发送给 LLM 进行分析的单条文本最大长度。
ANALYSIS_TEXT_TRUNCATION_LIMIT=200

# Enable Background Scheduler? / 是否启用后台调度器？
# Controls periodic subscription tasks. / 控制定期订阅任务的执行。
SCHEDULER_ENABLED=true

# ==========================================
# AI Analysis Tuning (AI 分析参数调优)
# ==========================================

# --- Clustering (观点聚类) ---
# Min/Max number of key opinions to generate / 生成核心观点的最少/最大数量
OPINION_COUNT_MIN=2
OPINION_COUNT_MAX=6

# Adaptive thresholds / 自适应数量阈值
# If items <= 12, use min; if > 48, use max. / 数据量 <=12 用最小值，>48 用最大值。
OPINION_COUNT_THRESHOLDS=12,24,36,48

# --- Semantic Sampling (智能采样) ---
# Local Embedding Model / 本地 Embedding 模型
# A lightweight model for semantic vectorization. / 用于语义向量化的轻量级模型。
SEMANTIC_SAMPLING_MODEL=intfloat/multilingual-e5-small

# Max items to consider for sampling / 参与采样的最大数据量
# Items exceeding this are filtered by engagement score first. / 超过此数量的数据先按热度过滤。
SEMANTIC_SAMPLING_MAX_ITEMS=200

# Target items to send to LLM / 发送给 LLM 的目标数据量
# Controls cost vs coverage. / 控制成本与覆盖率平衡的核心参数。
SEMANTIC_SAMPLING_TARGET_COUNT=50

# K-Means Clusters Range / K-Means 聚类数量范围
# Determines diversity of sampled opinions. / 决定采样观点的多样性。
SEMANTIC_SAMPLING_K_MIN=3
SEMANTIC_SAMPLING_K_MAX=10

# Outlier Retention Ratio / 离群点保留比例
# Percentage of "unique" opinions to keep. / 保留“独特”长尾观点的比例。
SEMANTIC_SAMPLING_OUTLIER_RATIO=0.1

# Max text length per item / 单条数据最大文本长度
# Truncates long texts to save tokens. / 截断长文本以节省 Token。
SEMANTIC_SAMPLING_TEXT_MAX_LENGTH=400

# Batch size for embedding inference / Embedding 推理批次大小
# Adjust based on GPU/CPU memory. / 根据显存/内存大小调整。
SEMANTIC_SAMPLING_BATCH_SIZE=64